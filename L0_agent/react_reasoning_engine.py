"""ReActæ¨ç†å¼•æ“æ¨¡å—

è¯¥æ¨¡å—å®ç°äº†ReAct (Reasoning and Acting) æ¨ç†æ¡†æ¶ï¼Œæä¾›ï¼š
- å¤šè·³æ¨ç†è§„åˆ’å’Œæ‰§è¡Œ
- Thought-Action-Observationå¾ªç¯
- æ¨ç†é“¾ç®¡ç†å’Œä¾èµ–è¿½è¸ª
- æ™ºèƒ½å·¥å…·é€‰æ‹©å’Œå‚æ•°ä¼˜åŒ–
"""

import json
import uuid
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from openai import AsyncOpenAI

# ç»Ÿä¸€ä½¿ç”¨ç»å¯¹å¯¼å…¥ï¼Œé¿å…ç±»å‹æ£€æŸ¥é—®é¢˜
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from L0_agent_state import AgentState, ReActStep, ReasoningChain

from config import config
import logging


class ReActReasoningEngine:
    """ReActæ¨ç†å¼•æ“
    
    å®ç°Thought-Action-Observationå¾ªç¯çš„å¤šè·³æ¨ç†èƒ½åŠ›
    """
    
    def __init__(self, client: AsyncOpenAI = None):
        """åˆå§‹åŒ–æ¨ç†å¼•æ“
        
        å‚æ•°:
            client: OpenAIå®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼Œå°†æ ¹æ®æ¨¡å‹åŠ¨æ€åˆ›å»ºï¼‰
        """
        self.client = client
        self._client_cache = {}  # å®¢æˆ·ç«¯ç¼“å­˜
        self.logger = logging.getLogger(__name__)
    
    def _get_or_create_client(self, model_name: str) -> AsyncOpenAI:
        """è·å–æˆ–åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        å‚æ•°:
            model_name: æ¨¡å‹åç§°
            
        è¿”å›:
            OpenAIå®¢æˆ·ç«¯å®ä¾‹
        """
        if model_name not in self._client_cache:
            model_config = config.get_model_config(model_name)
            if not model_config:
                raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: {model_name}")
            
            self._client_cache[model_name] = AsyncOpenAI(
                api_key=model_config["api_key"],
                base_url=model_config["api_base"],
                timeout=30.0,
                max_retries=3
            )
        return self._client_cache[model_name]
    
    async def analyze_intent_with_reasoning(self, query: str, context: List[str], 
                                          reasoning_chain: Optional[ReasoningChain] = None) -> Dict[str, Any]:
        """ä½¿ç”¨ReActæ¡†æ¶åˆ†ææ„å›¾å¹¶è§„åˆ’æ¨ç†
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            reasoning_chain: ç°æœ‰æ¨ç†é“¾
            
        è¿”å›:
            åŒ…å«æ¨ç†ç»“æœçš„å­—å…¸
        """
        print(f"\n=== ReActæ¨ç†å¼•æ“: æ„å›¾åˆ†æ ===")
        
        # é¦–å…ˆè¯„ä¼°æŸ¥è¯¢å¤æ‚åº¦
        complexity_assessment = await self._assess_query_complexity(query, context)
        print(f"ğŸ¯ å¤æ‚åº¦è¯„ä¼°: {complexity_assessment}")
        
        # ç”Ÿæˆæ¨ç†æ€è€ƒ
        thought = await self._generate_react_thought(query, context, reasoning_chain)
        print(f"Thought: {thought}")
        
        # è§„åˆ’å¤šè·³æ¨ç†ï¼ˆå·²åŒ…å«å¤æ‚åº¦åˆ¤æ–­ï¼‰
        reasoning_plan = await self._plan_multi_hop_reasoning(query, thought, context)
        print(f"æ¨ç†è§„åˆ’: {reasoning_plan}")
        
        # é€‰æ‹©å½“å‰æ­¥éª¤çš„è¡ŒåŠ¨
        current_action = self._select_current_action(reasoning_plan, query)
        print(f"å½“å‰è¡ŒåŠ¨: {current_action}")
        
        return {
            'thoughts': [thought],
            'reasoning_chain': reasoning_chain,
            'reasoning_plan': reasoning_plan,
            'planned_actions': reasoning_plan,
            'current_action': current_action,
            'complexity_assessment': complexity_assessment  # æ–°å¢å¤æ‚åº¦è¯„ä¼°ä¿¡æ¯
        }
    
    async def _generate_react_thought(self, query: str, context: List[str], 
                                     reasoning_chain: Optional[ReasoningChain] = None) -> str:
        """ç”ŸæˆReActæ€è€ƒè¿‡ç¨‹
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            reasoning_chain: æ¨ç†é“¾
            
        è¿”å›:
            æ€è€ƒå†…å®¹
        """
        # æ„å»ºæ€è€ƒæç¤ºè¯
        context_str = "\n".join(context[-3:]) if context else "æ— "
        
        previous_steps = ""
        if reasoning_chain and reasoning_chain.steps:
            steps_summary = []
            for step in reasoning_chain.steps[-2:]:  # æœ€è¿‘2æ­¥
                steps_summary.append(f"æ€è€ƒ: {step.thought}\nè¡ŒåŠ¨: {step.action}\nè§‚å¯Ÿ: {step.observation}")
            previous_steps = "\n\n".join(steps_summary)
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ¨ç†åŠ©æ‰‹ï¼Œéœ€è¦åˆ†æç”¨æˆ·é—®é¢˜å¹¶è¿›è¡Œæ·±åº¦æ€è€ƒã€‚

ç”¨æˆ·é—®é¢˜: {query}

ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context_str}

ä¹‹å‰çš„æ¨ç†æ­¥éª¤:
{previous_steps if previous_steps else "æ— "}

è¯·è¿›è¡Œæ·±åº¦æ€è€ƒï¼Œåˆ†æè¿™ä¸ªé—®é¢˜éœ€è¦ä»€ä¹ˆä¿¡æ¯ï¼Œåº”è¯¥é‡‡å–ä»€ä¹ˆç­–ç•¥ã€‚
æ€è€ƒè¦ç‚¹:
1. é—®é¢˜çš„æ ¸å¿ƒæ˜¯ä»€ä¹ˆï¼Ÿ
2. éœ€è¦å“ªäº›ä¿¡æ¯æ¥å›ç­”ï¼Ÿ
3. ä¿¡æ¯ä¹‹é—´æœ‰ä»€ä¹ˆå…³è”ï¼Ÿ
4. åº”è¯¥é‡‡ç”¨ä»€ä¹ˆæ¨ç†ç­–ç•¥ï¼Ÿ

è¯·æä¾›ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ˆ100-200å­—ï¼‰:"""
        
        try:
            model_name = config.system_config['default_model']
            client = self._get_or_create_client(model_name)
            model_config = config.get_model_config(model_name)
            
            response = await client.chat.completions.create(
                model=model_config["model"],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¨ç†åˆ†æå¸ˆï¼Œæ“…é•¿æ·±åº¦æ€è€ƒå’Œé€»è¾‘åˆ†æã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=300
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ€è€ƒè¿‡ç¨‹å¤±è´¥: {e}")
            return f"åˆ†æé—®é¢˜: {query}ï¼Œéœ€è¦æ”¶é›†ç›¸å…³ä¿¡æ¯è¿›è¡Œå›ç­”ã€‚"
    
    async def _assess_query_complexity(self, query: str, context: List[str]) -> Dict[str, Any]:
        """è¯„ä¼°æŸ¥è¯¢å¤æ‚åº¦
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        è¿”å›:
            å¤æ‚åº¦è¯„ä¼°ç»“æœ
        """
        prompt = f"""åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢çš„å¤æ‚ç¨‹åº¦ï¼Œå¹¶åˆ¤æ–­æ‰€éœ€çš„æ¨ç†ç­–ç•¥ã€‚

ç”¨æˆ·æŸ¥è¯¢: {query}
ä¸Šä¸‹æ–‡: {context[:2] if context else ['æ— ']}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°:
1. **ä¿¡æ¯éœ€æ±‚å¤æ‚åº¦**: æ˜¯å¦éœ€è¦å¤šä¸ªä¿¡æ¯æºï¼Ÿ
2. **æ¨ç†æ­¥éª¤å¤æ‚åº¦**: æ˜¯å¦éœ€è¦å¤šæ­¥é€»è¾‘æ¨ç†ï¼Ÿ
3. **æ—¶é—´ä¾èµ–æ€§**: æ˜¯å¦æ¶‰åŠæ—¶é—´åºåˆ—æˆ–å› æœå…³ç³»ï¼Ÿ
4. **çŸ¥è¯†æ•´åˆåº¦**: æ˜¯å¦éœ€è¦æ•´åˆå¤šé¢†åŸŸçŸ¥è¯†ï¼Ÿ

å¤æ‚åº¦åˆ†ç±»:
- **ç®€å•**: å•ä¸€æ˜ç¡®ä¿¡æ¯æŸ¥è¯¢ï¼ˆå¦‚"å…¬å¸åœ°å€"ã€"äº§å“ä»·æ ¼"ã€"å‘˜å·¥æ‰‹å†Œå†…å®¹"ï¼‰
- **ä¸­ç­‰**: éœ€è¦ç®€å•æ¨ç†æˆ–æ¯”è¾ƒï¼ˆå¦‚"æœ€æ–°äº§å“ç‰¹æ€§å¯¹æ¯”"ã€"æ–‡æ¡£æ‘˜è¦"ï¼‰
- **å¤æ‚**: éœ€è¦å¤šæ­¥æ¨ç†ã€æ—¶é—´å…³è”æˆ–è·¨é¢†åŸŸæ•´åˆï¼ˆå¦‚"æ¯”èµ›å½“å¤©æ°”æ¸©"ã€"å¤šæ¡ä»¶ç­›é€‰"ï¼‰

è¾“å‡ºJSONæ ¼å¼:
{{
    "complexity_level": "simple|medium|complex",
    "reasoning_strategy": "direct|simplified|multi_hop",
    "estimated_steps": 1-4,
    "key_factors": ["å› ç´ 1", "å› ç´ 2"],
    "confidence": 0.0-1.0
}}"""
        
        try:
            model_name = config.system_config['default_model']
            client = self._get_or_create_client(model_name)
            model_config = config.get_model_config(model_name)
            
            response = await client.chat.completions.create(
                model=model_config["model"],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢å¤æ‚åº¦åˆ†æä¸“å®¶ï¼Œèƒ½å¤Ÿå‡†ç¡®è¯„ä¼°é—®é¢˜çš„æ¨ç†éš¾åº¦ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=300
            )
            
            result = response.choices[0].message.content.strip()
            
            # è§£æJSON
            try:
                json_start = result.find('{')
                json_end = result.rfind('}') + 1
                if json_start != -1 and json_end > json_start:
                    json_content = result[json_start:json_end]
                    complexity_result = json.loads(json_content)
                    return complexity_result
            except json.JSONDecodeError:
                pass
            
            # é»˜è®¤è¿”å›ä¸­ç­‰å¤æ‚åº¦
            return {
                "complexity_level": "medium",
                "reasoning_strategy": "simplified",
                "estimated_steps": 2,
                "key_factors": ["é»˜è®¤è¯„ä¼°"],
                "confidence": 0.5
            }
            
        except Exception as e:
            self.logger.error(f"å¤æ‚åº¦è¯„ä¼°å¤±è´¥: {e}")
            return {
                "complexity_level": "medium",
                "reasoning_strategy": "simplified",
                "estimated_steps": 2,
                "key_factors": ["è¯„ä¼°å¤±è´¥"],
                "confidence": 0.3
            }
    
    async def _plan_simple_reasoning(self, query: str, thought: str, context: List[str]) -> List[Dict[str, Any]]:
        """ç®€å•é—®é¢˜æ¨ç†è§„åˆ’ï¼šç›´æ¥æœç´¢ â†’ éªŒè¯è¾“å‡º
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            thought: æ€è€ƒè¿‡ç¨‹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        è¿”å›:
            ç®€åŒ–çš„æ¨ç†æ­¥éª¤åˆ—è¡¨
        """
        return [
            {
                "step_id": 1,
                "description": f"æœç´¢æŸ¥è¯¢ç›¸å…³ä¿¡æ¯: {query}",
                "tool": "local_document_rag_search",
                "reasoning": "ç›´æ¥æœç´¢æœ¬åœ°çŸ¥è¯†åº“è·å–ç­”æ¡ˆ",
                "dependencies": []
            },
            {
                "step_id": 2,
                "description": "éªŒè¯ä¿¡æ¯å‡†ç¡®æ€§å¹¶ç”Ÿæˆç­”æ¡ˆ",
                "tool": "verification",
                "reasoning": "ç¡®ä¿ä¿¡æ¯å‡†ç¡®å¹¶è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ",
                "dependencies": [1]
            }
        ]
    
    async def _plan_simplified_reasoning(self, query: str, thought: str, context: List[str]) -> List[Dict[str, Any]]:
        """ä¸­ç­‰é—®é¢˜æ¨ç†è§„åˆ’ï¼šæœ¬åœ°æœç´¢ â†’ è¡¥å……æœç´¢ â†’ æ•´åˆè¾“å‡º
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            thought: æ€è€ƒè¿‡ç¨‹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        è¿”å›:
            ç®€åŒ–çš„æ¨ç†æ­¥éª¤åˆ—è¡¨
        """
        return [
            {
                "step_id": 1,
                "description": f"è·å–åŸºç¡€ä¿¡æ¯: {query}",
                "tool": "local_document_rag_search",
                "reasoning": "é¦–å…ˆä»æœ¬åœ°çŸ¥è¯†åº“è·å–åŸºç¡€ä¿¡æ¯",
                "dependencies": []
            },
            {
                "step_id": 2,
                "description": "è¡¥å……æˆ–éªŒè¯ä¿¡æ¯",
                "tool": "internet_search",
                "reasoning": "è¡¥å……æœ€æ–°ä¿¡æ¯æˆ–éªŒè¯æœ¬åœ°ä¿¡æ¯",
                "dependencies": [1]
            },
            {
                "step_id": 3,
                "description": "æ•´åˆä¿¡æ¯å¹¶ç”Ÿæˆå®Œæ•´ç­”æ¡ˆ",
                "tool": "summary",
                "reasoning": "æ•´åˆæ‰€æœ‰ä¿¡æ¯æä¾›å®Œæ•´å›ç­”",
                "dependencies": [1, 2]
            }
        ]
    
    async def _plan_complex_reasoning(self, query: str, thought: str, context: List[str]) -> List[Dict[str, Any]]:
        """å¤æ‚é—®é¢˜æ¨ç†è§„åˆ’ï¼šå®Œæ•´å¤šè·³æ¨ç†
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            thought: æ€è€ƒè¿‡ç¨‹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        è¿”å›:
            å®Œæ•´çš„æ¨ç†æ­¥éª¤åˆ—è¡¨
        """
        # ä¿æŒåŸæœ‰çš„å¤æ‚æ¨ç†é€»è¾‘
        return await self._plan_original_multi_hop_reasoning(query, thought, context)
    
    async def _plan_original_multi_hop_reasoning(self, query: str, thought: str, context: List[str]) -> List[Dict[str, Any]]:
        """åŸå§‹çš„å¤šè·³æ¨ç†è§„åˆ’é€»è¾‘
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            thought: æ€è€ƒè¿‡ç¨‹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        è¿”å›:
            æ¨ç†æ­¥éª¤è§„åˆ’åˆ—è¡¨
        """
        prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œè§„åˆ’è§£å†³ç”¨æˆ·é—®é¢˜çš„æ¨ç†æ­¥éª¤ã€‚

ç”¨æˆ·é—®é¢˜: {query}
æ€è€ƒåˆ†æ: {thought}

å¯ç”¨å·¥å…·:
1. local_document_rag_search - æœç´¢æœ¬åœ°æ–‡æ¡£å’ŒçŸ¥è¯†åº“
2. internet_search - è”ç½‘æœç´¢æœ€æ–°ä¿¡æ¯
3. mcp_service_search - ä½¿ç”¨MCPæœåŠ¡æ£€ç´¢

è¯·è§„åˆ’2-4ä¸ªæ¨ç†æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å«:
- step_id: æ­¥éª¤ç¼–å·
- description: æ­¥éª¤æè¿°ï¼ˆè¦å…·ä½“æ˜ç¡®ï¼Œä¾¿äºç”Ÿæˆç²¾ç¡®çš„æœç´¢æŸ¥è¯¢ï¼‰
- tool: ä½¿ç”¨çš„å·¥å…·
- reasoning: é€‰æ‹©è¯¥å·¥å…·çš„ç†ç”±
- dependencies: ä¾èµ–çš„å‰ç½®æ­¥éª¤ï¼ˆå¦‚æœæœ‰ï¼‰

é‡è¦è¦æ±‚:
1. ç¬¬ä¸€æ­¥å’Œç¬¬äºŒæ­¥çš„descriptionåº”è¯¥æ˜ç¡®è¦æŸ¥æ‰¾çš„å…·ä½“ä¿¡æ¯ï¼ˆå¦‚æ—¥æœŸã€åœ°ç‚¹ç­‰ï¼‰
2. ç¬¬ä¸‰æ­¥å’Œç¬¬å››æ­¥åº”è¯¥æ˜¯éªŒè¯å’Œæ€»ç»“æ­¥éª¤ï¼Œä¸è°ƒç”¨å·¥å…·
3. æ¯ä¸ªæ­¥éª¤éƒ½è¦æœ‰æ˜ç¡®çš„ç›®æ ‡ï¼Œé¿å…æ¨¡ç³Šæè¿°
4. å·¥å…·é€‰æ‹©è§„åˆ™ï¼šå‰ä¸¤æ­¥ä½¿ç”¨æœç´¢å·¥å…·ï¼Œåä¸¤æ­¥ä½¿ç”¨verificationæˆ–summary

ç¤ºä¾‹ï¼ˆé’ˆå¯¹"è‹è¶…å—äº¬VSè‹å·æ¯”èµ›å½“å¤©çš„åŒ—äº¬æ°”æ¸©"ï¼‰:
[
  {{
    "step_id": 1,
    "description": "ç¡®å®šè‹è¶…å—äº¬VSè‹å·æ¯”èµ›çš„å…·ä½“æ—¥æœŸ",
    "tool": "internet_search",
    "reasoning": "éœ€è¦å…ˆç¡®å®šæ¯”èµ›æ—¥æœŸæ‰èƒ½æŸ¥è¯¢å½“å¤©æ°”æ¸©",
    "dependencies": []
  }},
  {{
    "step_id": 2,
    "description": "æŸ¥è¯¢æ¯”èµ›æ—¥æœŸå½“å¤©åŒ—äº¬çš„æ°”æ¸©æ•°æ®",
    "tool": "internet_search",
    "reasoning": "æ ¹æ®ç¬¬ä¸€æ­¥è·å¾—çš„æ—¥æœŸæŸ¥è¯¢å…·ä½“æ°”æ¸©",
    "dependencies": [1]
  }},
  {{
    "step_id": 3,
    "description": "éªŒè¯æ¯”èµ›æ—¥æœŸå’Œæ°”æ¸©ä¿¡æ¯çš„å‡†ç¡®æ€§",
    "tool": "verification",
    "reasoning": "ç¡®ä¿è·å¾—çš„ä¿¡æ¯å‡†ç¡®å¯é ",
    "dependencies": [1, 2]
  }},
  {{
    "step_id": 4,
    "description": "ç»¼åˆä¿¡æ¯ç”Ÿæˆå®Œæ•´ç­”æ¡ˆ",
    "tool": "summary",
    "reasoning": "æ•´åˆæ‰€æœ‰ä¿¡æ¯æä¾›å®Œæ•´å›ç­”",
    "dependencies": [1, 2, 3]
  }}
]

è¾“å‡ºJSONæ ¼å¼:
[
  {{
    "step_id": 1,
    "description": "æ­¥éª¤æè¿°",
    "tool": "å·¥å…·åç§°",
    "reasoning": "é€‰æ‹©ç†ç”±",
    "dependencies": []
  }}
]"""
        
        try:
            model_name = config.system_config['default_model']
            client = self._get_or_create_client(model_name)
            model_config = config.get_model_config(model_name)
            
            response = await client.chat.completions.create(
                model=model_config["model"],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ¨ç†è§„åˆ’ä¸“å®¶ï¼Œèƒ½å¤Ÿå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ¸…æ™°çš„æ­¥éª¤ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            result = response.choices[0].message.content.strip()
            
            # è§£æJSON
            try:
                json_start = result.find('[')
                json_end = result.rfind(']') + 1
                if json_start != -1 and json_end > json_start:
                    json_content = result[json_start:json_end]
                    plan = json.loads(json_content)
                    return plan
            except json.JSONDecodeError:
                pass
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤è§„åˆ’
            return [
                {
                    "step_id": 1,
                    "description": "æœç´¢ç›¸å…³ä¿¡æ¯",
                    "tool": "local_document_rag_search",
                    "reasoning": "é¦–å…ˆä»æœ¬åœ°çŸ¥è¯†åº“è·å–åŸºç¡€ä¿¡æ¯",
                    "dependencies": []
                }
            ]
            
        except Exception as e:
            self.logger.error(f"è§„åˆ’æ¨ç†æ­¥éª¤å¤±è´¥: {e}")
            return [
                {
                    "step_id": 1,
                    "description": "æœç´¢ç›¸å…³ä¿¡æ¯",
                    "tool": "local_document_rag_search",
                    "reasoning": "è·å–åŸºç¡€ä¿¡æ¯",
                    "dependencies": []
                }
            ]
    
    async def _plan_multi_hop_reasoning(self, query: str, thought: str, context: List[str]) -> List[Dict[str, Any]]:
        """è§„åˆ’å¤šè·³æ¨ç†æ­¥éª¤ - å¢å¼ºå¤æ‚åº¦åˆ¤æ–­
        
        å‚æ•°:
            query: ç”¨æˆ·æŸ¥è¯¢
            thought: æ€è€ƒè¿‡ç¨‹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        è¿”å›:
            æ¨ç†æ­¥éª¤è§„åˆ’åˆ—è¡¨
        """
        # 1. é¦–å…ˆè¯„ä¼°æŸ¥è¯¢å¤æ‚åº¦
        complexity_assessment = await self._assess_query_complexity(query, context)
        complexity_level = complexity_assessment.get('complexity_level', 'medium')
        reasoning_strategy = complexity_assessment.get('reasoning_strategy', 'simplified')
        
        print(f"ğŸ¯ å¤æ‚åº¦è¯„ä¼°: {complexity_level} | ç­–ç•¥: {reasoning_strategy}")
        
        # 2. æ ¹æ®å¤æ‚åº¦é€‰æ‹©ä¸åŒçš„æ¨ç†è·¯å¾„
        if complexity_level == "simple" and reasoning_strategy == "direct":
            # ç®€å•é—®é¢˜ï¼šç›´æ¥è·¯å¾„
            plan = await self._plan_simple_reasoning(query, thought, context)
        elif complexity_level == "medium" and reasoning_strategy == "simplified":
            # ä¸­ç­‰é—®é¢˜ï¼šç®€åŒ–è·¯å¾„
            plan = await self._plan_simplified_reasoning(query, thought, context)
        else:
            # å¤æ‚é—®é¢˜ï¼šå®Œæ•´å¤šè·³æ¨ç†
            plan = await self._plan_complex_reasoning(query, thought, context)
        
        # 3. åœ¨è®¡åˆ’ä¸­æ·»åŠ å¤æ‚åº¦ä¿¡æ¯
        for step in plan:
            step['complexity_level'] = complexity_level
            step['reasoning_strategy'] = reasoning_strategy
        
        return plan
        prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œè§„åˆ’è§£å†³ç”¨æˆ·é—®é¢˜çš„æ¨ç†æ­¥éª¤ã€‚

ç”¨æˆ·é—®é¢˜: {query}
æ€è€ƒåˆ†æ: {thought}

å¯ç”¨å·¥å…·:
1. local_document_rag_search - æœç´¢æœ¬åœ°æ–‡æ¡£å’ŒçŸ¥è¯†åº“
2. internet_search - è”ç½‘æœç´¢æœ€æ–°ä¿¡æ¯
3. mcp_service_search - ä½¿ç”¨MCPæœåŠ¡æ£€ç´¢

è¯·è§„åˆ’2-4ä¸ªæ¨ç†æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å«:
- step_id: æ­¥éª¤ç¼–å·
- description: æ­¥éª¤æè¿°ï¼ˆè¦å…·ä½“æ˜ç¡®ï¼Œä¾¿äºç”Ÿæˆç²¾ç¡®çš„æœç´¢æŸ¥è¯¢ï¼‰
- tool: ä½¿ç”¨çš„å·¥å…·
- reasoning: é€‰æ‹©è¯¥å·¥å…·çš„ç†ç”±
- dependencies: ä¾èµ–çš„å‰ç½®æ­¥éª¤ï¼ˆå¦‚æœæœ‰ï¼‰

é‡è¦è¦æ±‚:
1. ç¬¬ä¸€æ­¥å’Œç¬¬äºŒæ­¥çš„descriptionåº”è¯¥æ˜ç¡®è¦æŸ¥æ‰¾çš„å…·ä½“ä¿¡æ¯ï¼ˆå¦‚æ—¥æœŸã€åœ°ç‚¹ç­‰ï¼‰
2. ç¬¬ä¸‰æ­¥å’Œç¬¬å››æ­¥åº”è¯¥æ˜¯éªŒè¯å’Œæ€»ç»“æ­¥éª¤ï¼Œä¸è°ƒç”¨å·¥å…·
3. æ¯ä¸ªæ­¥éª¤éƒ½è¦æœ‰æ˜ç¡®çš„ç›®æ ‡ï¼Œé¿å…æ¨¡ç³Šæè¿°
4. å·¥å…·é€‰æ‹©è§„åˆ™ï¼šå‰ä¸¤æ­¥ä½¿ç”¨æœç´¢å·¥å…·ï¼Œåä¸¤æ­¥ä½¿ç”¨verificationæˆ–summary

ç¤ºä¾‹ï¼ˆé’ˆå¯¹"è‹è¶…å—äº¬VSè‹å·æ¯”èµ›å½“å¤©çš„åŒ—äº¬æ°”æ¸©"ï¼‰:
[
  {{
    "step_id": 1,
    "description": "ç¡®å®šè‹è¶…å—äº¬VSè‹å·æ¯”èµ›çš„å…·ä½“æ—¥æœŸ",
    "tool": "internet_search",
    "reasoning": "éœ€è¦å…ˆç¡®å®šæ¯”èµ›æ—¥æœŸæ‰èƒ½æŸ¥è¯¢å½“å¤©æ°”æ¸©",
    "dependencies": []
  }},
  {{
    "step_id": 2,
    "description": "æŸ¥è¯¢æ¯”èµ›æ—¥æœŸå½“å¤©åŒ—äº¬çš„æ°”æ¸©æ•°æ®",
    "tool": "internet_search",
    "reasoning": "æ ¹æ®ç¬¬ä¸€æ­¥è·å¾—çš„æ—¥æœŸæŸ¥è¯¢å…·ä½“æ°”æ¸©",
    "dependencies": [1]
  }},
  {{
    "step_id": 3,
    "description": "éªŒè¯æ¯”èµ›æ—¥æœŸå’Œæ°”æ¸©ä¿¡æ¯çš„å‡†ç¡®æ€§",
    "tool": "verification",
    "reasoning": "ç¡®ä¿è·å¾—çš„ä¿¡æ¯å‡†ç¡®å¯é ",
    "dependencies": [1, 2]
  }},
  {{
    "step_id": 4,
    "description": "ç»¼åˆä¿¡æ¯ç”Ÿæˆå®Œæ•´ç­”æ¡ˆ",
    "tool": "summary",
    "reasoning": "æ•´åˆæ‰€æœ‰ä¿¡æ¯æä¾›å®Œæ•´å›ç­”",
    "dependencies": [1, 2, 3]
  }}
]

è¾“å‡ºJSONæ ¼å¼:
[
  {{
    "step_id": 1,
    "description": "æ­¥éª¤æè¿°",
    "tool": "å·¥å…·åç§°",
    "reasoning": "é€‰æ‹©ç†ç”±",
    "dependencies": []
  }}
]"""
        
        try:
            model_name = config.system_config['default_model']
            client = self._get_or_create_client(model_name)
            model_config = config.get_model_config(model_name)
            
            response = await client.chat.completions.create(
                model=model_config["model"],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ¨ç†è§„åˆ’ä¸“å®¶ï¼Œèƒ½å¤Ÿå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ¸…æ™°çš„æ­¥éª¤ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=800
            )
            
            result = response.choices[0].message.content.strip()
            
            # è§£æJSON
            try:
                json_start = result.find('[')
                json_end = result.rfind(']') + 1
                if json_start != -1 and json_end > json_start:
                    json_content = result[json_start:json_end]
                    plan = json.loads(json_content)
                    return plan
            except json.JSONDecodeError:
                pass
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤è§„åˆ’
            return [
                {
                    "step_id": 1,
                    "description": "æœç´¢ç›¸å…³ä¿¡æ¯",
                    "tool": "local_document_rag_search",
                    "reasoning": "é¦–å…ˆä»æœ¬åœ°çŸ¥è¯†åº“è·å–åŸºç¡€ä¿¡æ¯",
                    "dependencies": []
                }
            ]
            
        except Exception as e:
            self.logger.error(f"è§„åˆ’æ¨ç†æ­¥éª¤å¤±è´¥: {e}")
            return [
                {
                    "step_id": 1,
                    "description": "æœç´¢ç›¸å…³ä¿¡æ¯",
                    "tool": "local_document_rag_search",
                    "reasoning": "è·å–åŸºç¡€ä¿¡æ¯",
                    "dependencies": []
                }
            ]
    
    def _select_current_action(self, reasoning_plan: List[Dict[str, Any]], query: str = "") -> Dict[str, Any]:
        """é€‰æ‹©å½“å‰åº”æ‰§è¡Œçš„è¡ŒåŠ¨
        
        å‚æ•°:
            reasoning_plan: æ¨ç†è§„åˆ’
            query: ç”¨æˆ·æŸ¥è¯¢ï¼ˆç”¨äºç”Ÿæˆå‚æ•°ï¼‰
            
        è¿”å›:
            å½“å‰è¡ŒåŠ¨
        """
        if not reasoning_plan:
            return {
                "tool": "local_document_rag_search",
                "description": "æœç´¢ç›¸å…³ä¿¡æ¯",
                "parameters": {"query": query} if query else {"query": "æœç´¢ç›¸å…³ä¿¡æ¯"}
            }
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªæœªå®Œæˆçš„æ­¥éª¤
        current_step = reasoning_plan[0]
        tool_name = current_step.get("tool", "local_document_rag_search")
        
        # æ ¹æ®å·¥å…·ç±»å‹ç”Ÿæˆåˆé€‚çš„å‚æ•°
        parameters = current_step.get("parameters", {})
        if not parameters:
            # ä¼˜å…ˆä½¿ç”¨æ­¥éª¤æè¿°ï¼Œè¿™æ ·æ›´ç²¾ç¡®
            step_query = current_step.get("description", query or "æœç´¢ç›¸å…³ä¿¡æ¯")
            if tool_name == "local_document_rag_search":
                parameters = {"query": step_query}
            elif tool_name == "internet_search":
                parameters = {"query": step_query}
            elif tool_name == "mcp_service_search":
                parameters = {"query": step_query}
            else:
                parameters = {"query": step_query}
        
        return {
            "tool": tool_name,
            "description": current_step.get("description", "æ‰§è¡Œæ¨ç†æ­¥éª¤"),
            "parameters": parameters,
            "reasoning": current_step.get("reasoning", "")
        }
    
    async def rewrite_query_for_next_step(self, original_query: str, step_description: str, 
                                         previous_results: str, step_index: int) -> str:
        """ä¸ºä¸‹ä¸€æ­¥æ¨ç†æ”¹å†™æŸ¥è¯¢
        
        å‚æ•°:
            original_query: åŸå§‹ç”¨æˆ·æŸ¥è¯¢
            step_description: å½“å‰æ­¥éª¤æè¿°
            previous_results: å‰é¢æ­¥éª¤çš„ç»“æœ
            step_index: å½“å‰æ­¥éª¤ç´¢å¼•
            
        è¿”å›:
            æ”¹å†™åçš„æŸ¥è¯¢
        """
        if step_index == 0:
            # ç¬¬ä¸€æ­¥ï¼Œæ ¹æ®æ„å›¾åˆ†ææ”¹å†™æŸ¥è¯¢
            return await self._rewrite_first_step_query(original_query, step_description)
        else:
            # åç»­æ­¥éª¤ï¼Œç»“åˆå‰é¢çš„ç»“æœæ”¹å†™æŸ¥è¯¢
            return await self._rewrite_subsequent_step_query(
                original_query, step_description, previous_results, step_index
            )
    
    async def _rewrite_first_step_query(self, original_query: str, step_description: str) -> str:
        """æ”¹å†™ç¬¬ä¸€æ­¥æŸ¥è¯¢
        
        å‚æ•°:
            original_query: åŸå§‹æŸ¥è¯¢
            step_description: æ­¥éª¤æè¿°
            
        è¿”å›:
            æ”¹å†™åçš„æŸ¥è¯¢
        """
        prompt = f"""æ ¹æ®ç”¨æˆ·çš„åŸå§‹é—®é¢˜å’Œæ¨ç†æ­¥éª¤æè¿°ï¼Œæ”¹å†™ä¸€ä¸ªæ›´ç²¾ç¡®çš„æœç´¢æŸ¥è¯¢ã€‚

åŸå§‹é—®é¢˜: {original_query}
æ¨ç†æ­¥éª¤: {step_description}

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´ã€ç²¾ç¡®çš„æœç´¢æŸ¥è¯¢ï¼Œä¸“æ³¨äºè¿™ä¸€æ­¥éœ€è¦è·å–çš„ä¿¡æ¯ã€‚
åªè¿”å›æ”¹å†™åçš„æŸ¥è¯¢ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""
        
        try:
            model_name = config.system_config['default_model']
            client = self._get_or_create_client(model_name)
            model_config = config.get_model_config(model_name)
            
            response = await client.chat.completions.create(
                model=model_config["model"],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢æ”¹å†™ä¸“å®¶ï¼Œèƒ½å¤Ÿæ ¹æ®æ¨ç†æ­¥éª¤ç”Ÿæˆç²¾ç¡®çš„æœç´¢æŸ¥è¯¢ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=100
            )
            
            rewritten_query = response.choices[0].message.content.strip()
            return rewritten_query if rewritten_query else step_description
            
        except Exception as e:
            self.logger.error(f"æ”¹å†™ç¬¬ä¸€æ­¥æŸ¥è¯¢å¤±è´¥: {e}")
            return step_description
    
    async def _rewrite_subsequent_step_query(self, original_query: str, step_description: str, 
                                           previous_results: str, step_index: int) -> str:
        """æ”¹å†™åç»­æ­¥éª¤æŸ¥è¯¢
        
        å‚æ•°:
            original_query: åŸå§‹æŸ¥è¯¢
            step_description: æ­¥éª¤æè¿°
            previous_results: å‰é¢æ­¥éª¤çš„ç»“æœ
            step_index: æ­¥éª¤ç´¢å¼•
            
        è¿”å›:
            æ”¹å†™åçš„æŸ¥è¯¢
        """
        # ç›´æ¥ä½¿ç”¨å‰é¢æ­¥éª¤çš„ç»“æœä½œä¸ºå…³é”®ä¿¡æ¯
        key_info = previous_results[:1000] if len(previous_results) > 1000 else previous_results
        
        prompt = f"""ä½ éœ€è¦æ ¹æ®å‰é¢æ­¥éª¤çš„ç»“æœæ”¹å†™ä¸€ä¸ªç²¾ç¡®çš„æœç´¢æŸ¥è¯¢ã€‚

ã€å‰é¢æ­¥éª¤çš„ç»“æœã€‘:
{key_info}

ã€å½“å‰ä»»åŠ¡ã€‘: {step_description}

ã€å…³é”®è¦æ±‚ã€‘:
1. ä»”ç»†é˜…è¯»å‰é¢æ­¥éª¤çš„ç»“æœï¼Œæå–å…¶ä¸­çš„å…³é”®ä¿¡æ¯ï¼ˆç‰¹åˆ«æ˜¯æ—¥æœŸã€åœ°ç‚¹ç­‰ï¼‰
2. åŸºäºæå–çš„ä¿¡æ¯ç”Ÿæˆæœç´¢æŸ¥è¯¢
3. å¦‚æœå‰é¢æ­¥éª¤æåˆ°äº†å…·ä½“æ—¥æœŸï¼ˆå¦‚2025å¹´7æœˆ5æ—¥ï¼‰ï¼Œå¿…é¡»åœ¨æŸ¥è¯¢ä¸­ä½¿ç”¨è¿™ä¸ªç¡®åˆ‡æ—¥æœŸ
4. æŸ¥è¯¢æ ¼å¼è¦ç®€æ´æ˜ç¡®ï¼Œå¦‚"2025å¹´7æœˆ5æ—¥åŒ—äº¬æ°”æ¸©"

ã€ç¤ºä¾‹ã€‘:
- å¦‚æœå‰é¢ç»“æœæ˜¾ç¤º"æ¯”èµ›æ—¶é—´ï¼š2025å¹´7æœˆ5æ—¥"ï¼Œä¸”å½“å‰ä»»åŠ¡æ˜¯æŸ¥è¯¢æ°”æ¸©ï¼Œåˆ™åº”ç”Ÿæˆ"2025å¹´7æœˆ5æ—¥åŒ—äº¬æ°”æ¸©"
- å¦‚æœå‰é¢ç»“æœæ˜¾ç¤º"æ¯”èµ›æ—¶é—´ï¼š2024å¹´3æœˆ15æ—¥"ï¼Œä¸”å½“å‰ä»»åŠ¡æ˜¯æŸ¥è¯¢å¤©æ°”ï¼Œåˆ™åº”ç”Ÿæˆ"2024å¹´3æœˆ15æ—¥åŒ—äº¬å¤©æ°”"

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚ï¼Œåªè¿”å›æ”¹å†™åçš„æŸ¥è¯¢ï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼š"""
        
        try:
            model_name = config.system_config['default_model']
            client = self._get_or_create_client(model_name)
            model_config = config.get_model_config(model_name)
            
            response = await client.chat.completions.create(
                model=model_config["model"],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢æ”¹å†™ä¸“å®¶ï¼Œèƒ½å¤Ÿç»“åˆå‰é¢æ­¥éª¤çš„ç»“æœç”Ÿæˆç²¾ç¡®çš„æœç´¢æŸ¥è¯¢ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=150
            )
            
            rewritten_query = response.choices[0].message.content.strip()
            return rewritten_query if rewritten_query else step_description
            
        except Exception as e:
            self.logger.error(f"æ”¹å†™åç»­æ­¥éª¤æŸ¥è¯¢å¤±è´¥: {e}")
            return step_description
    

    
    async def execute_reasoning_step(self, state: AgentState, action: Dict[str, Any], 
                                   tool_result: Any) -> ReActStep:
        """æ‰§è¡Œæ¨ç†æ­¥éª¤å¹¶è®°å½•
        
        å‚æ•°:
            state: å½“å‰çŠ¶æ€
            action: æ‰§è¡Œçš„è¡ŒåŠ¨
            tool_result: å·¥å…·æ‰§è¡Œç»“æœ
            
        è¿”å›:
            æ¨ç†æ­¥éª¤è®°å½•
        """
        # ç”Ÿæˆè§‚å¯Ÿç»“æœ
        observation = await self._generate_observation(action, tool_result, state)
        
        # åˆ›å»ºæ¨ç†æ­¥éª¤
        step = ReActStep(
            step_id=state['react_step'] + 1,
            thought=state['thought_history'][-1] if state['thought_history'] else "æ‰§è¡Œæ¨ç†æ­¥éª¤",
            action=f"{action['tool']}: {action['description']}",
            action_input=action.get('parameters', {}),
            observation=observation
        )
        
        # æ›´æ–°æ¨ç†é“¾
        if state['reasoning_chain']:
            state['reasoning_chain'].steps.append(step)
        
        return step
    
    async def _generate_observation(self, action: Dict[str, Any], tool_result: Any, 
                                  state: AgentState) -> str:
        """ç”Ÿæˆè§‚å¯Ÿç»“æœ
        
        å‚æ•°:
            action: æ‰§è¡Œçš„è¡ŒåŠ¨
            tool_result: å·¥å…·ç»“æœ
            state: å½“å‰çŠ¶æ€
            
        è¿”å›:
            è§‚å¯Ÿç»“æœæè¿°
        """
        if not tool_result or not hasattr(tool_result, 'success'):
            return "å·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œæœªè·å¾—æœ‰æ•ˆç»“æœã€‚"
        
        if not tool_result.success:
            return f"å·¥å…·æ‰§è¡Œå¤±è´¥: {tool_result.error or 'æœªçŸ¥é”™è¯¯'}"
        
        # è¿”å›å®é™…çš„å·¥å…·æ‰§è¡Œç»“æœå†…å®¹
        content = tool_result.content if tool_result.content else ""
        content_length = len(content)
        
        if content_length == 0:
            return "å·¥å…·æ‰§è¡ŒæˆåŠŸï¼Œä½†æœªè¿”å›ä»»ä½•å†…å®¹ã€‚"
        elif content_length < 50:
            # å¯¹äºç®€çŸ­å†…å®¹ï¼Œç›´æ¥è¿”å›å®Œæ•´å†…å®¹
            return content
        elif content_length < 500:
            # å¯¹äºä¸­ç­‰é•¿åº¦å†…å®¹ï¼Œè¿”å›å®Œæ•´å†…å®¹
            return content
        else:
            # å¯¹äºé•¿å†…å®¹ï¼Œè¿”å›å‰500ä¸ªå­—ç¬¦å¹¶æ·»åŠ çœç•¥å·
            return content[:500] + "...(å†…å®¹å·²æˆªæ–­)"
    
    async def comprehensive_reflection(self, state: AgentState) -> Dict[str, Any]:
        """ç»¼åˆåæ€è¯„ä¼°
        
        å‚æ•°:
            state: å½“å‰çŠ¶æ€
            
        è¿”å›:
            åæ€ç»“æœ
        """
        print(f"\n=== ReActæ¨ç†å¼•æ“: ç»¼åˆåæ€ ===")
        
        # åˆ†ææ¨ç†é“¾å®Œæ•´æ€§
        chain_analysis = self._analyze_reasoning_chain(state)
        
        # è¯„ä¼°ç­”æ¡ˆè´¨é‡
        answer_quality = await self._evaluate_answer_quality(state)
        
        # ç¡®å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
        next_action = self._determine_next_action(state, chain_analysis, answer_quality)
        
        return {
            'chain_analysis': chain_analysis,
            'answer_quality': answer_quality,
            'next_action': next_action,
            'reflection_result': next_action['decision']
        }
    
    def _analyze_reasoning_chain(self, state: AgentState) -> Dict[str, Any]:
        """åˆ†ææ¨ç†é“¾å®Œæ•´æ€§
        
        å‚æ•°:
            state: å½“å‰çŠ¶æ€
            
        è¿”å›:
            æ¨ç†é“¾åˆ†æç»“æœ
        """
        chain = state.get('reasoning_chain')
        if not chain or not hasattr(chain, 'steps') or not chain.steps:
            return {
                'completeness': 0.0,
                'issues': ['æ¨ç†é“¾ä¸ºç©º'],
                'suggestions': ['éœ€è¦å¼€å§‹æ¨ç†è¿‡ç¨‹']
            }
        
        # åˆ†ææ­¥éª¤å®Œæ•´æ€§
        completed_steps = len([s for s in chain.steps if s.observation])
        total_planned = len(state.get('reasoning_plan', []))
        
        completeness = completed_steps / max(total_planned, 1)
        
        issues = []
        suggestions = []
        
        if completeness < 0.5:
            issues.append('æ¨ç†æ­¥éª¤ä¸å®Œæ•´')
            suggestions.append('éœ€è¦ç»§ç»­æ‰§è¡Œæ¨ç†æ­¥éª¤')
        
        if not state.get('retrieved_info'):
            issues.append('ç¼ºä¹ä¿¡æ¯æ”¯æ’‘')
            suggestions.append('éœ€è¦è·å–æ›´å¤šä¿¡æ¯')
        
        return {
            'completeness': completeness,
            'completed_steps': completed_steps,
            'total_planned': total_planned,
            'issues': issues,
            'suggestions': suggestions
        }
    
    async def _evaluate_answer_quality(self, state: AgentState) -> Dict[str, Any]:
        """è¯„ä¼°ç­”æ¡ˆè´¨é‡
        
        å‚æ•°:
            state: å½“å‰çŠ¶æ€
            
        è¿”å›:
            ç­”æ¡ˆè´¨é‡è¯„ä¼°
        """
        if not state.get('current_answer'):
            return {
                'score': 0.0,
                'issues': ['æ²¡æœ‰ç”Ÿæˆç­”æ¡ˆ'],
                'strengths': []
            }
        
        answer = state['current_answer']
        query = state['query']
        
        # åŸºç¡€è´¨é‡æ£€æŸ¥
        issues = []
        strengths = []
        
        if len(answer) < 50:
            issues.append('ç­”æ¡ˆè¿‡äºç®€çŸ­')
        else:
            strengths.append('ç­”æ¡ˆé•¿åº¦é€‚ä¸­')
        
        if 'æŠ±æ­‰' in answer or 'æ— æ³•' in answer:
            issues.append('ç­”æ¡ˆè¡¨è¾¾ä¸ç¡®å®šæ€§')
        else:
            strengths.append('ç­”æ¡ˆè¡¨è¾¾ç¡®å®š')
        
        if state.get('retrieved_info'):
            strengths.append('åŸºäºæ£€ç´¢ä¿¡æ¯ç”Ÿæˆ')
        else:
            issues.append('ç¼ºä¹ä¿¡æ¯æ”¯æ’‘')
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        score = max(0.0, min(1.0, len(strengths) / max(len(strengths) + len(issues), 1)))
        
        return {
            'score': score,
            'issues': issues,
            'strengths': strengths
        }
    
    def _determine_next_action(self, state: AgentState, chain_analysis: Dict[str, Any], 
                             answer_quality: Dict[str, Any]) -> Dict[str, Any]:
        """ç¡®å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
        
        å‚æ•°:
            state: å½“å‰çŠ¶æ€
            chain_analysis: æ¨ç†é“¾åˆ†æ
            answer_quality: ç­”æ¡ˆè´¨é‡è¯„ä¼°
            
        è¿”å›:
            ä¸‹ä¸€æ­¥è¡ŒåŠ¨å†³ç­–
        """
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        if state.get('iteration_count', 0) >= 5:
            return {
                'decision': 'sufficient',
                'reason': 'è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°',
                'action': 'finalize'
            }
        
        # æ£€æŸ¥ç­”æ¡ˆè´¨é‡
        if answer_quality['score'] >= 0.7 and len(answer_quality['issues']) <= 1:
            return {
                'decision': 'sufficient',
                'reason': 'ç­”æ¡ˆè´¨é‡è‰¯å¥½',
                'action': 'finalize'
            }
        
        # æ£€æŸ¥æ¨ç†é“¾å®Œæ•´æ€§
        if chain_analysis['completeness'] < 0.8:
            return {
                'decision': 'insufficient',
                'reason': 'æ¨ç†é“¾ä¸å®Œæ•´ï¼Œéœ€è¦ç»§ç»­æ¨ç†',
                'action': 'continue_reasoning'
            }
        
        # æ£€æŸ¥ä¿¡æ¯å……åˆ†æ€§
        if not state.get('retrieved_info') or len(state.get('retrieved_info', '')) < 100:
            return {
                'decision': 'insufficient',
                'reason': 'ä¿¡æ¯ä¸è¶³ï¼Œéœ€è¦æ›´å¤šæ£€ç´¢',
                'action': 'gather_more_info'
            }
        
        # é»˜è®¤ç»§ç»­æ¨ç†
        return {
            'decision': 'insufficient',
            'reason': 'éœ€è¦è¿›ä¸€æ­¥å®Œå–„ç­”æ¡ˆ',
            'action': 'continue_reasoning'
        }